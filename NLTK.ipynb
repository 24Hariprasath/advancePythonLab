{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz2QQcARSJ/DAuZr6oYZh4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/24Hariprasath/advancePythonLab/blob/main/NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Toolkit (NLTK) library to perform Part-of-Speech (POS) tagging on a given text."
      ],
      "metadata": {
        "id": "33ER5dUKzcVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLcViH74zX1b",
        "outputId": "dedbd13d-5492-413e-8952-daf0fae11235"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVslu_bLzSB9",
        "outputId": "59867f22-2ab1-4abd-a556-b3e38aaf46f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "text = \"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum\"\n",
        "\n",
        "words = nltk.word_tokenize(text)\n",
        "\n",
        "\n",
        "pos_tags = nltk.pos_tag(words)\n",
        "\n",
        "print(\"Part-of-Speech Tags:\")\n",
        "for word, tag in pos_tags:\n",
        "    print(f\"{word} --> {tag}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF_5bHKJzvjg",
        "outputId": "2d6edf13-9b51-4c3d-b675-0414e509ab95"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part-of-Speech Tags:\n",
            "Lorem --> NNP\n",
            "Ipsum --> NNP\n",
            "is --> VBZ\n",
            "simply --> RB\n",
            "dummy --> JJ\n",
            "text --> NN\n",
            "of --> IN\n",
            "the --> DT\n",
            "printing --> NN\n",
            "and --> CC\n",
            "typesetting --> NN\n",
            "industry --> NN\n",
            ". --> .\n",
            "Lorem --> NNP\n",
            "Ipsum --> NNP\n",
            "has --> VBZ\n",
            "been --> VBN\n",
            "the --> DT\n",
            "industry --> NN\n",
            "'s --> POS\n",
            "standard --> JJ\n",
            "dummy --> NN\n",
            "text --> NN\n",
            "ever --> RB\n",
            "since --> IN\n",
            "the --> DT\n",
            "1500s --> CD\n",
            ", --> ,\n",
            "when --> WRB\n",
            "an --> DT\n",
            "unknown --> JJ\n",
            "printer --> NN\n",
            "took --> VBD\n",
            "a --> DT\n",
            "galley --> NN\n",
            "of --> IN\n",
            "type --> NN\n",
            "and --> CC\n",
            "scrambled --> VBD\n",
            "it --> PRP\n",
            "to --> TO\n",
            "make --> VB\n",
            "a --> DT\n",
            "type --> NN\n",
            "specimen --> NNS\n",
            "book --> NN\n",
            ". --> .\n",
            "It --> PRP\n",
            "has --> VBZ\n",
            "survived --> VBN\n",
            "not --> RB\n",
            "only --> RB\n",
            "five --> CD\n",
            "centuries --> NNS\n",
            ", --> ,\n",
            "but --> CC\n",
            "also --> RB\n",
            "the --> DT\n",
            "leap --> NN\n",
            "into --> IN\n",
            "electronic --> JJ\n",
            "typesetting --> NN\n",
            ", --> ,\n",
            "remaining --> VBG\n",
            "essentially --> RB\n",
            "unchanged --> JJ\n",
            ". --> .\n",
            "It --> PRP\n",
            "was --> VBD\n",
            "popularised --> VBN\n",
            "in --> IN\n",
            "the --> DT\n",
            "1960s --> NNS\n",
            "with --> IN\n",
            "the --> DT\n",
            "release --> NN\n",
            "of --> IN\n",
            "Letraset --> NNP\n",
            "sheets --> NNS\n",
            "containing --> VBG\n",
            "Lorem --> NNP\n",
            "Ipsum --> NNP\n",
            "passages --> NNS\n",
            ", --> ,\n",
            "and --> CC\n",
            "more --> RBR\n",
            "recently --> RB\n",
            "with --> IN\n",
            "desktop --> NN\n",
            "publishing --> NN\n",
            "software --> NN\n",
            "like --> IN\n",
            "Aldus --> NNP\n",
            "PageMaker --> NNP\n",
            "including --> VBG\n",
            "versions --> NNS\n",
            "of --> IN\n",
            "Lorem --> NNP\n",
            "Ipsum --> NNP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nouns = [word for word, tag in pos_tags if tag.startswith('NN')]\n",
        "verbs = [word for word, tag in pos_tags if tag.startswith('VB')]\n",
        "adjectives = [word for word, tag in pos_tags if tag.startswith('JJ')]\n",
        "\n",
        "print(\"Nouns:\", nouns)\n",
        "print(\"Verbs:\", verbs)\n",
        "print(\"Adjectives:\", adjectives)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fahQMrme2BLM",
        "outputId": "c51f114b-84ef-48dc-8764-9b221a15ce4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nouns: ['Lorem', 'Ipsum', 'text', 'printing', 'typesetting', 'industry', 'Lorem', 'Ipsum', 'industry', 'dummy', 'text', 'printer', 'galley', 'type', 'type', 'specimen', 'book', 'centuries', 'leap', 'typesetting', '1960s', 'release', 'Letraset', 'sheets', 'Lorem', 'Ipsum', 'passages', 'desktop', 'publishing', 'software', 'Aldus', 'PageMaker', 'versions', 'Lorem', 'Ipsum']\n",
            "Verbs: ['is', 'has', 'been', 'took', 'scrambled', 'make', 'has', 'survived', 'remaining', 'was', 'popularised', 'containing', 'including']\n",
            "Adjectives: ['dummy', 'standard', 'unknown', 'electronic', 'unchanged']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "tag_freq = Counter(tag for word, tag in pos_tags)\n",
        "print(\"POS Tag Frequencies:\", tag_freq)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u_YLAGh2Kqo",
        "outputId": "3e354367-810d-488c-ff20-6f0ff54adcc0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tag Frequencies: Counter({'NN': 18, 'NNP': 11, 'IN': 10, 'DT': 9, 'RB': 7, 'NNS': 6, 'JJ': 5, 'CC': 4, ',': 4, 'VBZ': 3, '.': 3, 'VBN': 3, 'VBD': 3, 'PRP': 3, 'VBG': 3, 'CD': 2, 'POS': 1, 'WRB': 1, 'TO': 1, 'VB': 1, 'RBR': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word, tag in pos_tags if word.lower() not in stop_words]\n",
        "print(\"Without stopwords:\", filtered_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk5XPKh72Ud6",
        "outputId": "88c92c48-b9bf-4e38-cce7-a2b04bf181b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without stopwords: ['Lorem', 'Ipsum', 'simply', 'dummy', 'text', 'printing', 'typesetting', 'industry', '.', 'Lorem', 'Ipsum', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', '1500s', ',', 'unknown', 'printer', 'took', 'galley', 'type', 'scrambled', 'make', 'type', 'specimen', 'book', '.', 'survived', 'five', 'centuries', ',', 'also', 'leap', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.', 'popularised', '1960s', 'release', 'Letraset', 'sheets', 'containing', 'Lorem', 'Ipsum', 'passages', ',', 'recently', 'desktop', 'publishing', 'software', 'like', 'Aldus', 'PageMaker', 'including', 'versions', 'Lorem', 'Ipsum']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook. I practiced the package NLTK which gives me foundation idea about NLP and methods in NLP like tokenization, lemminization, tagging a word, and lot other. I performed some basic operations on the sample text to get familiar with the funtionalities"
      ],
      "metadata": {
        "id": "QZ8y1wRk2YII"
      }
    }
  ]
}